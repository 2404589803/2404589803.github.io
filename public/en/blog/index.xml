<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on GLM</title>
    <link>http://localhost:1313/en/blog/</link>
    <description>Recent content in Blogs on GLM</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 04 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/en/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CogVideoX:A Cutting-Edge Video Generation Models</title>
      <link>http://localhost:1313/en/blog/cogvideox----a-cutting-edge-video-generation-model/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/en/blog/cogvideox----a-cutting-edge-video-generation-model/</guid>
      <description>As a highly complex system, human cognitive function relies on the collaborative work between various regions of the brain, which involves not only the processing of text and language, but also multiple aspects such as visual understanding and auditory processing.&#xA;We firmly believe that the integration and improvement of perception and understanding in Multi-modal Learning is closely related to the development of cognitive abilities.&#xA;As a company dedicated to achieving Artificial General Intelligence (AGI), ZhipuAI has always attached great importance to the development of MultiModal Machine Learning technology.</description>
    </item>
    <item>
      <title>GLM Long: Scaling Pre-trained Model Contexts to Millions</title>
      <link>http://localhost:1313/en/blog/glm-long-----caling-pre-trained-model-contexts-to-millions/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/en/blog/glm-long-----caling-pre-trained-model-contexts-to-millions/</guid>
      <description>In early 2023, even the most advanced GPT-3.5 had a context length of only 2k. However, today, a context length of 1M has become one of the important indicators for measuring the technological advancement of models.&#xA;If LLM is compared to the operating system of the new era, the context window is its &amp;ldquo;memory&amp;rdquo;. A modern operating system requires sufficient memory to complete various complex tasks. Similarly, an excellent LLM also requires sufficient context length to complete various complex tasks.</description>
    </item>
  </channel>
</rss>

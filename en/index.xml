<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GLM</title><link>https://2404589803.github.io/en/</link><description>Recent content on GLM</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 06 Aug 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://2404589803.github.io/en/index.xml" rel="self" type="application/rss+xml"/><item><title> CogVideoX-2B: China's open source sora</title><link>https://2404589803.github.io/en/blog/cogvideox-2b----------chinas-open-source-sora/</link><pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><guid>https://2404589803.github.io/en/blog/cogvideox-2b----------chinas-open-source-sora/</guid><description>With the continuous development of large-scale model technology, video generation technology is gradually maturing. Technologies represented by closed-source video generative models such as Sora and Gen-3 are redefining the future pattern of the industry. However, as of now, there is still no open-source video generative model that can meet the requirements of commercial-grade applications.
Zhipu AI adheres to the concept of &amp;ldquo;serving global developers with advanced technology&amp;rdquo; and announces the open source of CogVideoX, a video generative model with the same origin as &amp;ldquo;Qingying&amp;rdquo;, in order to allow every developer and every enterprise to freely develop their own video generative model, thereby promoting the rapid iteration and innovative development of the entire industry.</description></item><item><title>About US</title><link>https://2404589803.github.io/en/page/about/</link><pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate><guid>https://2404589803.github.io/en/page/about/</guid><description>We are a leading artificial intelligence company in China, focused on developing advanced AI technologies and applications. We specializes in natural language processing, machine learning, and data analysis, offering solutions that enhance business intelligence and operational efficiency. We provides a range of products and services, including AI-driven data platforms, intelligent customer service, and AI education platforms. We innovative solutions cater to various industries, aiming to drive digital transformation and improve decision-making processes.</description></item><item><title>CogVideoX:A Cutting-Edge Video Generation Models</title><link>https://2404589803.github.io/en/blog/cogvideox----a-cutting-edge-video-generation-model/</link><pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate><guid>https://2404589803.github.io/en/blog/cogvideox----a-cutting-edge-video-generation-model/</guid><description>As a highly complex system, human cognitive function relies on the collaborative work between various regions of the brain, which involves not only the processing of text and language, but also multiple aspects such as visual understanding and auditory processing.
We firmly believe that the integration and improvement of perception and understanding in Multi-modal Learning is closely related to the development of cognitive abilities.
As a company dedicated to achieving Artificial General Intelligence (AGI), ZhipuAI has always attached great importance to the development of MultiModal Machine Learning technology.</description></item><item><title>GLM Long: Scaling Pre-trained Model Contexts to Millions</title><link>https://2404589803.github.io/en/blog/glm-long-----caling-pre-trained-model-contexts-to-millions/</link><pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate><guid>https://2404589803.github.io/en/blog/glm-long-----caling-pre-trained-model-contexts-to-millions/</guid><description>In early 2023, even the most advanced GPT-3.5 had a context length of only 2k. However, today, a context length of 1M has become one of the important indicators for measuring the technological advancement of models.
If LLM is compared to the operating system of the new era, the context window is its &amp;ldquo;memory&amp;rdquo;. A modern operating system requires sufficient memory to complete various complex tasks. Similarly, an excellent LLM also requires sufficient context length to complete various complex tasks.</description></item></channel></rss>
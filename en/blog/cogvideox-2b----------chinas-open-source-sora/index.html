<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=/favicon.svg><title>CogVideoX-2B: China's open source sora - GLM
</title><meta name=description content="With the continuous development of large-scale model technology, video generation technology is gradually maturing. Technologies represented by closed-source video generative models such as Sora and Gen-3 are redefining the future pattern of the industry. However, as of now, there is still no open-source video generative model that can meet the requirements of commercial-grade applications.
Zhipu AI adheres to the concept of &ldquo;serving global developers with advanced technology&rdquo; and announces the open source of CogVideoX, a video generative model with the same origin as &ldquo;Qingying&rdquo;, in order to allow every developer and every enterprise to freely develop their own video generative model, thereby promoting the rapid iteration and innovative development of the entire industry."><meta name=generator content="Hugo 0.131.0"><link rel=stylesheet href="https://2404589803.github.io/css/styles.min.604fd6ddfbcfaf51795dc18d21ded1d9f7eadf8b91a4651731bdbacc8585608d.css" integrity="sha256-YE/W3fvPr1F5XcGNId7R2ffq34uRpGUXMb26zIWFYI0="><meta property="og:url" content="https://2404589803.github.io/en/blog/cogvideox-2b----------chinas-open-source-sora/"><meta property="og:site_name" content="GLM"><meta property="og:title" content=" CogVideoX-2B: China's open source sora "><meta property="og:description" content="With the continuous development of large-scale model technology, video generation technology is gradually maturing. Technologies represented by closed-source video generative models such as Sora and Gen-3 are redefining the future pattern of the industry. However, as of now, there is still no open-source video generative model that can meet the requirements of commercial-grade applications.
Zhipu AI adheres to the concept of “serving global developers with advanced technology” and announces the open source of CogVideoX, a video generative model with the same origin as “Qingying”, in order to allow every developer and every enterprise to freely develop their own video generative model, thereby promoting the rapid iteration and innovative development of the entire industry."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-08-06T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-06T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content=" CogVideoX-2B: China's open source sora "><meta name=twitter:description content="With the continuous development of large-scale model technology, video generation technology is gradually maturing. Technologies represented by closed-source video generative models such as Sora and Gen-3 are redefining the future pattern of the industry. However, as of now, there is still no open-source video generative model that can meet the requirements of commercial-grade applications.
Zhipu AI adheres to the concept of “serving global developers with advanced technology” and announces the open source of CogVideoX, a video generative model with the same origin as “Qingying”, in order to allow every developer and every enterprise to freely develop their own video generative model, thereby promoting the rapid iteration and innovative development of the entire industry."><meta itemprop=name content=" CogVideoX-2B: China's open source sora "><meta itemprop=description content="With the continuous development of large-scale model technology, video generation technology is gradually maturing. Technologies represented by closed-source video generative models such as Sora and Gen-3 are redefining the future pattern of the industry. However, as of now, there is still no open-source video generative model that can meet the requirements of commercial-grade applications.
Zhipu AI adheres to the concept of “serving global developers with advanced technology” and announces the open source of CogVideoX, a video generative model with the same origin as “Qingying”, in order to allow every developer and every enterprise to freely develop their own video generative model, thereby promoting the rapid iteration and innovative development of the entire industry."><meta itemprop=datePublished content="2024-08-06T00:00:00+00:00"><meta itemprop=dateModified content="2024-08-06T00:00:00+00:00"><meta itemprop=wordCount content="327"></head><body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Document</title>
<link href=https://cdn.jsdelivr.net/npm/tailwindcss@3.2.4/dist/tailwind.min.css rel=stylesheet><style>.header-container{transition:background-color .3s,color .3s}.language-dropdown{display:none}.language-switcher:hover .language-dropdown{display:flex}</style></head><body><header class="header-container container flex justify-between items-center p-6 mx-auto relative sticky top-0 z-50 bg-white"><a href=https://2404589803.github.io/en/ class="header-title capitalize font-extrabold text-2xl"><img src=/blist-logo.png alt=GLM class="h-8 max-w-full"></a><ul class="flex items-center gap-4 lg:gap-6"><li><a href=/en/>Home</a></li><li><a href=/en/blog>Blog</a></li><li><a href=/en/page/about/>About</a></li><div class="bg-white dark:bg-gray-900"><div><div class="text-2xl font-bold mb-2"></div><p class=opacity-60></p></div><ul class="flex justify-center gap-x-3 flex-wrap gap-y-2"><li><a href=https://x.com/ChatGLM target=_blank rel=noopener aria-label=Twitter class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li><li><a href=https://github.com/THUDM target=_blank rel=noopener aria-label=GitHub class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.334 1.333-4.334-2.667-6-3m12 3v-2.26A3.5 3.5.0 0014.06 14c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0019 3.19a5.07 5.07.0 00-.09-3.81s-1.18-.35-3.91 1.48a13.38 13.38.0 00-7.02.0c-2.73-1.83-3.91-1.48-3.91-1.48a5.07 5.07.0 00-.09 3.81A5.44 5.44.0 002.48 7c0 5.42 3.3 6.65 6.44 7a3.5 3.5.0 00-.94 2.74V19"/></svg></a></li><li><a href=https://www.youtube.com/channel/UCSpG1gG4VdTFYBViakDFt8g target=_blank rel=noopener aria-label=YouTube class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="4"/><path d="M10 9l5 3-5 3z"/></svg></a></li></ul></div></ul></header><script>document.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".header-container");window.addEventListener("scroll",()=>{window.scrollY>50?e.classList.add("bg-white"):e.classList.remove("bg-white")})})</script></body></html><main class=flex-1><div class="relative max-w-5xl mx-auto px-4"><img src=/CogVideoX-2B.png class="rounded-lg shadow-sm w-full object-contain"><div class="absolute top-4 right-8 rounded shadow bg-white text-gray-900 dark:bg-gray-900 dark:text-white px-2 py-0.5">August 6, 2024</div></div><article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4"><h1 class="text-2xl font-bold mb-2">CogVideoX-2B: China's open source sora</h1><h5 class="text-sm flex items-center flex-wrap"><svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="5" width="16" height="16" rx="2"/><line x1="16" y1="3" x2="16" y2="7"/><line x1="8" y1="3" x2="8" y2="7"/><line x1="4" y1="11" x2="20" y2="11"/><rect x="8" y="15" width="2" height="2"/></svg>
Posted on
August 6, 2024
&nbsp;&bull;&nbsp;
<svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
2&nbsp;minutes
&nbsp;&bull;
<svg class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 19a9 9 0 019 0 9 9 0 019 0"/><path d="M3 6a9 9 0 019 0 9 9 0 019 0"/><line x1="3" y1="6" x2="3" y2="19"/><line x1="12" y1="6" x2="12" y2="19"/><line x1="21" y1="6" x2="21" y2="19"/></svg>
327&nbsp;words</h5><details id=TableOfContents class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc"><summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white"><span>Table of contents</span><svg class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><polyline points="6 9 12 15 18 9"/></svg></summary><ul class="mt-2 pb-4"><li><a href=#model>Model</a><ul><li><a href=#vae>VAE</a></li></ul></li></ul></details><p>With the continuous development of large-scale model technology, video generation technology is gradually maturing. Technologies represented by closed-source video generative models such as Sora and Gen-3 are redefining the future pattern of the industry. However, as of now, there is still no open-source video generative model that can meet the requirements of commercial-grade applications.</p><p>Zhipu AI adheres to the concept of &ldquo;serving global developers with advanced technology&rdquo; and announces the open source of CogVideoX, a video generative model with the same origin as &ldquo;Qingying&rdquo;, in order to allow every developer and every enterprise to freely develop their own video generative model, thereby promoting the rapid iteration and innovative development of the entire industry.</p><p>CogVideoX open source model contains a number of different sizes of models , we will open source CogVideoX-2B , it inference in FP-16 precision only 18GB memory, fine-tuning only requires 40GB memory, which means that a single 4090 graphics card can be inferred, and a single A6000 graphics card can complete fine-tuning.</p><p>CogVideoX -2B has a maximum of 226 tokens for prompt words, a video length of 6 seconds, a frame rate of 8 frames per second, and a video resolution of 720 * 480. We have reserved a broad space for improving video quality and look forward to developers contributing to open source efforts in prompt word optimization, video length, frame rate, resolution, scene fine-tuning, and various feature development around videos.</p><p>Models with stronger performance and larger parameters are on the way , please pay attention and look forward to it.1</p><p>*<em>Code repository: <a href=https://github.com/THUDM/CogVideo target=_blank rel=noopener>https://github.com/THUDM/CogVideo</a></em></p><p>*<em>Model download: <a href=https://huggingface.co/THUDM/CogVideoX-2b target=_blank rel=noopener>https://huggingface.co/THUDM/CogVideoX-2b</a></em></p><p>*<em>Experience link: <a href=https://huggingface.co/spaces/THUDM/CogVideoX target=_blank rel=noopener>https://huggingface.co/spaces/THUDM/CogVideoX</a></em></p><p>*<em>Technical Report: <a href=https://github.com/THUDM/CogVideo/blob/main/resources/CogVideoX.pdf target=_blank rel=noopener>https://github.com/THUDM/CogVideo/blob/main/resources/CogVideoX.pdf</a></em></p><h2 id=model>Model</h2><p><img alt="alt text" src=/img_v3_02dg_dad99112-a43a-4e4e-82cc-c28243c1095g.png></p><h3 id=vae>VAE</h3><p>Video data contains spatial and temporal information, and its data volume and computational burden far exceed that of image data. To address this challenge, we propose a video compression method based on 3D variational autoencoder (3D VAE). 3D VAE compresses the spatial and temporal dimensions of video through 3D convolution, achieving higher compression rate and better reconstruction quality.</p></article><div class="px-2 mb-2"><script src=https://giscus.app/client.js data-repo data-repo-id data-category data-category-id data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></div></main><footer class="container p-6 mx-auto flex justify-between items-center"><span class="text-sm font-light">Copyright © 2024 - Zhipu AI · All rights reserved
</span><span onclick='window.scrollTo({top:0,behavior:"smooth"})' class="p-1 cursor-pointer"><svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12"/></svg></span></footer><script>const mobileMenuButton=document.querySelector(".mobile-menu-button"),mobileMenu=document.querySelector(".mobile-menu");function toggleMenu(){mobileMenu.classList.toggle("hidden"),mobileMenu.classList.toggle("flex")}mobileMenu&&mobileMenuButton&&mobileMenuButton.addEventListener("click",toggleMenu)</script></body></html>